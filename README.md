 # MLAT-CE: Multi-Level Attention Transformer with Context Enhancement

## Описание

MLAT-CE (Multi-Level Attention Transformer with Context Enhancement) — это архитектура для генерации текста, в которой есть элементы как LSTM так и Transformers , подчеркиваются новые способности , такие как многоуровневое внимание и динамическая нормализация. Эту архитектуру я сделал как эксперимент для создания улучшенной версии архитектуры нейросетей.

## Особенности

- **Многоуровневое внимание (Multi-Level Attention):** Добавление нескольких уровней внимания для улучшения понимания контекста.
- **Динамическая нормализация (Dynamic Normalization):** Использование динамической нормализации для стабилизации обучения.
